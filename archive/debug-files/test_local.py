#!/usr/bin/env python3
"""
æœ¬åœ°æµ‹è¯•è„šæœ¬ - ä¸ä¾èµ–å¤–éƒ¨æ¨¡å‹ä¸‹è½½
"""
import torch
from src.flux.model import Flux, FluxParams
from src.flux.modules.autoencoder import AutoEncoder, AutoEncoderParams
from src.flux.modules.conditioner import HFEmbedder
from src.flux.sampling import get_noise, get_schedule

def test_model_creation():
    """æµ‹è¯•æ¨¡å‹åˆ›å»ºæ˜¯å¦æ­£å¸¸"""
    print("ğŸ§ª æµ‹è¯•æ¨¡å‹åˆ›å»º...")
    
    # åˆ›å»ºå°ä¸€ç‚¹çš„æµ‹è¯•å‚æ•°
    flux_params = FluxParams(
        in_channels=16,  # å‡å°
        vec_in_dim=768,
        context_in_dim=768,  # å‡å°
        hidden_size=512,  # å‡å°
        mlp_ratio=2.0,  # å‡å°
        num_heads=8,  # å‡å°
        depth=2,  # å‡å°
        depth_single_blocks=2,  # å‡å°
        axes_dim=[16, 28, 28],  # å‡å°
        theta=10_000,
        qkv_bias=True,
        guidance_embed=True,
    )
    
    ae_params = AutoEncoderParams(
        resolution=64,  # å‡å°
        in_channels=3,
        ch=64,  # å‡å°
        out_ch=3,
        ch_mult=[1, 2],  # å‡å°
        num_res_blocks=1,  # å‡å°
        z_channels=8,  # å‡å°
        scale_factor=0.3611,
        shift_factor=0.1159,
    )
    
    try:
        # æµ‹è¯• Flux æ¨¡å‹åˆ›å»º
        print("  âœ“ åˆ›å»º Flux æ¨¡å‹...")
        model = Flux(flux_params)
        print(f"  âœ“ Flux æ¨¡å‹åˆ›å»ºæˆåŠŸ: {sum(p.numel() for p in model.parameters()):,} å‚æ•°")
        
        # æµ‹è¯• AutoEncoder åˆ›å»º
        print("  âœ“ åˆ›å»º AutoEncoder...")
        ae = AutoEncoder(ae_params)
        print(f"  âœ“ AutoEncoder åˆ›å»ºæˆåŠŸ: {sum(p.numel() for p in ae.parameters()):,} å‚æ•°")
        
        # æµ‹è¯•æ•°æ®æµ
        print("  âœ“ æµ‹è¯•æ•°æ®æµ...")
        batch_size = 1
        img_size = 32
        seq_len = (img_size // 2) * (img_size // 2)
        
        # åˆ›å»ºæµ‹è¯•è¾“å…¥
        img = torch.randn(batch_size, seq_len, flux_params.in_channels)
        img_ids = torch.zeros(batch_size, seq_len, 3)
        txt = torch.randn(batch_size, 77, flux_params.context_in_dim)
        txt_ids = torch.zeros(batch_size, 77, 3) 
        timesteps = torch.randn(batch_size)
        y = torch.randn(batch_size, flux_params.vec_in_dim)
        guidance = torch.randn(batch_size) if flux_params.guidance_embed else None
        
        # å‰å‘ä¼ æ’­æµ‹è¯•
        with torch.no_grad():
            output = model(img, img_ids, txt, txt_ids, timesteps, y, guidance)
            print(f"  âœ“ æ¨¡å‹å‰å‘ä¼ æ’­æˆåŠŸ: è¾“å‡ºå½¢çŠ¶ {output.shape}")
        
        # æµ‹è¯• AutoEncoder
        test_img = torch.randn(1, 3, 64, 64)
        with torch.no_grad():
            encoded = ae.encode(test_img)
            decoded = ae.decode(encoded)
            print(f"  âœ“ AutoEncoder æµ‹è¯•æˆåŠŸ: {test_img.shape} -> {encoded.shape} -> {decoded.shape}")
        
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ä»£ç ç»“æ„æ­£ç¡®ã€‚")
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_sampling_functions():
    """æµ‹è¯•é‡‡æ ·ç›¸å…³å‡½æ•°"""
    print("\nğŸ§ª æµ‹è¯•é‡‡æ ·å‡½æ•°...")
    
    try:
        # æµ‹è¯•å™ªå£°ç”Ÿæˆ
        noise = get_noise(1, 64, 64, device="cpu", dtype=torch.float32, seed=42)
        print(f"  âœ“ å™ªå£°ç”ŸæˆæˆåŠŸ: {noise.shape}")
        
        # æµ‹è¯•æ—¶é—´æ­¥ç”Ÿæˆ
        timesteps = get_schedule(4, 64*64//4, shift=False)
        print(f"  âœ“ æ—¶é—´æ­¥ç”ŸæˆæˆåŠŸ: {len(timesteps)} æ­¥")
        
        print("ğŸ‰ é‡‡æ ·å‡½æ•°æµ‹è¯•é€šè¿‡ï¼")
        return True
        
    except Exception as e:
        print(f"âŒ é‡‡æ ·å‡½æ•°æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    print("ğŸš€ å¼€å§‹æµ‹è¯• FLUX ä»£ç ç»“æ„...")
    print("=" * 50)
    
    success1 = test_model_creation()
    success2 = test_sampling_functions()
    
    print("\n" + "=" * 50)
    if success1 and success2:
        print("âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ä½ çš„ FLUX å®ç°å·²å‡†å¤‡å°±ç»ªã€‚")
        print("\nğŸ“ è¦è¿è¡Œå®Œæ•´æ¨ç†ï¼Œä½ éœ€è¦:")
        print("1. åœ¨ https://huggingface.co æ³¨å†Œè´¦æˆ·")
        print("2. ç”³è¯·è®¿é—® FLUX æ¨¡å‹æƒé™")
        print("3. ä½¿ç”¨ 'huggingface-hub login' ç™»å½•")
        print("4. ç„¶åè¿è¡Œ: python3 inference.py -p 'your prompt' --device cpu")
    else:
        print("âŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä»£ç ã€‚")